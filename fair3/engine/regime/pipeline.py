"""Pipeline orchestrator for the regime probability engine."""

from __future__ import annotations

from collections.abc import Mapping
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import numpy as np
import pandas as pd

from fair3.engine.logging import setup_logger
from fair3.engine.regime.committee import regime_probability
from fair3.engine.utils.io import artifact_path, read_yaml
from fair3.engine.utils.rand import generator_from_seed

LOG = setup_logger(__name__)


@dataclass(slots=True)
class RegimePipelineResult:
    """Artefacts generated by the regime probability pipeline.

    Attributes:
      scores: DataFrame with regime probabilities and component diagnostics.
      probabilities_path: CSV path containing the full probability panel.
      hysteresis_path: CSV path containing the hysteresis regime flag.
      committee_log_path: CSV path logging the individual committee components.
      thresholds: Mapping with the thresholds applied during the run.
    """

    scores: pd.DataFrame
    probabilities_path: Path
    hysteresis_path: Path
    committee_log_path: Path
    thresholds: Mapping[str, Any]


def _load_thresholds(path: Path) -> Mapping[str, Any]:
    """Load the thresholds YAML returning a mapping."""

    payload = read_yaml(path)
    if isinstance(payload, Mapping):
        return payload
    LOG.warning("Threshold file %s is not a mapping; using defaults", path)
    return {}


def _read_asset_panel(clean_root: Path) -> pd.DataFrame | None:
    """Read the asset panel from disk returning None when unavailable."""

    asset_path = clean_root / "asset_panel.parquet"
    if not asset_path.exists():
        LOG.warning("asset_panel.parquet missing at %s", asset_path)
        return None

    panel = pd.read_parquet(asset_path)
    if {"date", "symbol", "field", "value"} - set(panel.columns):
        raise ValueError("asset_panel.parquet must include date, symbol, field, value columns")

    dates = pd.to_datetime(panel["date"], utc=True, errors="coerce")
    missing_dates = dates.isna().sum()
    if missing_dates:
        LOG.warning("Dropping %s rows with invalid dates from asset panel", missing_dates)
    panel = panel.loc[~dates.isna()].copy()
    panel["date"] = dates.loc[~dates.isna()].dt.tz_convert("Europe/Rome").dt.tz_localize(None)
    panel["value"] = pd.to_numeric(panel["value"], errors="coerce")
    panel = panel.dropna(subset=["value"])
    return panel


def _load_returns(asset_panel: pd.DataFrame | None, seed: int) -> pd.DataFrame:
    """Load returns from the asset panel or synthesise deterministic data."""

    if asset_panel is not None:
        for field in ("ret", "log_ret"):
            subset = asset_panel.loc[asset_panel["field"] == field]
            if subset.empty:
                continue
            wide = subset.pivot(index="date", columns="symbol", values="value").sort_index()
            if field == "log_ret":
                wide = np.expm1(wide)
            return wide.fillna(0.0)

    LOG.warning("Returns not found in asset panel; creating synthetic panel")
    idx = pd.date_range("2015-01-01", periods=252, freq="B")
    rng = generator_from_seed(seed)
    columns = ["SYN_EQ", "SYN_BND", "SYN_ALT"]
    data = rng.normal(0.0006, 0.01, size=(len(idx), len(columns)))
    return pd.DataFrame(data, index=idx, columns=columns)


def _load_volatility(asset_panel: pd.DataFrame | None, returns: pd.DataFrame) -> pd.Series:
    """Load realised volatility proxy from the asset panel or derive it."""

    if asset_panel is not None:
        vol_subset = asset_panel.loc[asset_panel["field"].isin({"lag_vol_21", "vol", "volatility"})]
        if not vol_subset.empty:
            vol_frame = vol_subset.pivot_table(
                index="date", columns="symbol", values="value", aggfunc="mean"
            ).sort_index()
            if not vol_frame.empty:
                return vol_frame.mean(axis=1).astype(float)

    LOG.info("lag_vol_21 not available in panel; estimating realised volatility from returns")
    window = 21
    vol = returns.rolling(window=window, min_periods=max(5, window // 2)).std()
    return vol.mean(axis=1) * (252**0.5)


def _synthesise_macro(index: pd.DatetimeIndex, seed: int) -> pd.DataFrame:
    """Generate deterministic macro series when real data is unavailable."""

    rng = generator_from_seed(seed + 42)
    trend = np.linspace(0.018, 0.023, len(index))
    inflation = trend + rng.normal(0.0, 0.0005, len(index))
    pmi = 52.0 - rng.normal(0.0, 0.8, len(index)).cumsum() / 20.0
    real_rate = -0.005 + rng.normal(0.0, 0.0007, len(index))
    return pd.DataFrame(
        {
            "inflation_yoy": inflation,
            "pmi": pmi,
            "real_rate": real_rate,
        },
        index=index,
    )


def _load_macro(
    asset_panel: pd.DataFrame | None, index: pd.DatetimeIndex, seed: int
) -> pd.DataFrame:
    """Load macro features from the asset panel or synthesise placeholders."""

    macro_fields = {"inflation_yoy", "pmi", "real_rate"}
    if asset_panel is not None:
        macro_subset = asset_panel.loc[asset_panel["field"].isin(macro_fields)]
        if not macro_subset.empty:
            frame = macro_subset.pivot_table(
                index="date", columns="field", values="value", aggfunc="mean"
            ).sort_index()
            if not frame.empty:
                return frame

        generic_macro = asset_panel.loc[asset_panel["field"] == "macro_field"]
        if not generic_macro.empty:
            pivot = generic_macro.pivot_table(
                index="date", columns="symbol", values="value", aggfunc="mean"
            ).sort_index()
            selected = [col for col in pivot.columns if col in macro_fields]
            if selected:
                return pivot[selected]

    LOG.info("Macro features unavailable; using synthetic deterministic series")
    return _synthesise_macro(index, seed)


def _assemble_panel(clean_root: Path, seed: int) -> pd.DataFrame:
    """Assemble the multi-field panel consumed by the regime engine."""

    asset_panel = _read_asset_panel(clean_root)
    returns = _load_returns(asset_panel, seed)
    vol = _load_volatility(asset_panel, returns)
    macro = _load_macro(asset_panel, returns.index, seed)

    frames = [pd.concat({"returns": returns}, axis=1)]
    if not vol.empty:
        frames.append(pd.concat({"volatility": vol.to_frame(name="vol")}, axis=1))
    if not macro.empty:
        frames.append(pd.concat({"macro": macro}, axis=1))
    panel = pd.concat(frames, axis=1)
    return panel.sort_index()


def run_regime_pipeline(
    *,
    clean_root: Path | str | None = None,
    thresholds_path: Path | str = Path("configs") / "thresholds.yml",
    output_dir: Path | str | None = None,
    seed: int = 0,
    dry_run: bool = False,
    trace: bool = False,
) -> RegimePipelineResult:
    """Run the regime probability engine and persist diagnostic artefacts."""

    clean_root = Path(clean_root) if clean_root is not None else Path("data") / "clean"
    thresholds_path = Path(thresholds_path)
    output_root = Path(output_dir) if output_dir is not None else None

    LOG.info("Starting regime pipeline clean_root=%s thresholds=%s", clean_root, thresholds_path)
    panel = _assemble_panel(clean_root, seed)
    thresholds = _load_thresholds(thresholds_path)
    scores = regime_probability(panel, thresholds, seed)
    if scores.empty:
        raise ValueError("Regime probability computation returned an empty frame")

    probabilities_path = artifact_path("regime", "probabilities.csv", root=output_root)
    scores.to_csv(probabilities_path, index_label="date")

    hysteresis_path = artifact_path("regime", "hysteresis.csv", root=output_root)
    scores[["regime_flag"]].to_csv(hysteresis_path, index_label="date")

    committee_columns = [col for col in ("p_hmm", "p_volatility", "p_macro") if col in scores]
    committee_log = scores[committee_columns].copy()
    committee_log["p_crisis"] = scores["p_crisis"]
    committee_log_path = artifact_path("regime", "committee_log.csv", root=output_root)
    committee_log.to_csv(committee_log_path, index_label="date")

    if trace:
        preview = scores.tail(5).to_string(float_format=lambda x: f"{x:.3f}")
        LOG.info("Regime preview (tail=5):\n%s", preview)

    LOG.info(
        "Regime pipeline complete dry_run=%s artifacts=(%s, %s, %s)",
        dry_run,
        probabilities_path,
        hysteresis_path,
        committee_log_path,
    )
    return RegimePipelineResult(
        scores=scores,
        probabilities_path=probabilities_path,
        hysteresis_path=hysteresis_path,
        committee_log_path=committee_log_path,
        thresholds=thresholds.get("regime", thresholds),
    )


__all__ = ["RegimePipelineResult", "run_regime_pipeline"]
